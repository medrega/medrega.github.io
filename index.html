<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="MedRegA">
  <meta name="keywords" content="medical multimodal large language model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MedRegA</title>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.27.0/gradio.js"></script>
</head>


<style>
  
	/* 使用渐变颜色实现彩虹字体 */
	.rainbow-text {
	  background: linear-gradient(to right, #7D8ABC, #AD88C6);
	  -webkit-background-clip: text;
	  color: transparent;
	  display: inline-block;
	  font-weight: bold;
	}
  
</style>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><img id="logo" width="5%" src="static/images/icon.png"> <span class="rainbow-text">MedRegA</span>: Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks</h1>
          <div class="is-size-5 publication-authors"> <span class="author-block"> <a href="https://luxuriant0116.github.io/">Lehan Wang</a><sup>1</sup>,</span> <span class="author-block"> <a href="https://haonanwang.tech/">Haonan Wanng</a><sup>1</sup>,</span> <span class="author-block"> <a href="https://medrega.github.io/">Honglong Yang</a><sup>1</sup>, </span> <span class="author-block"> <a href="https://medrega.github.io/">Jiaji Mao</a><sup>2</sup>, </span> <span class="author-block"> <a href="https://medrega.github.io/">Zehong Yang</a><sup>2</sup>, </span> <span class="author-block"> <a href="https://medrega.github.io/">Jun Shen</a><sup>2</sup>, </span> <span class="author-block"> <a href="https://xmengli.github.io/">Xiaomeng Li</a><sup>*1</sup></span> </div>
          <div class="is-size-5 publication-authors"> <span class="author-block"><sup>1</sup>The Hong Kong University of Science and Technology,</span> <span class="author-block"><sup>2</sup>Sun Yat-Sen Memorial Hospital, Sun Yat-Sen University</span>  </div>
		  <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>*</sup>Corresponding authors.</span>
            </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block"> <a href="https://arxiv.org/abs/2410.18387"
                   class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fas fa-file-pdf"></i> </span> <span>Paper</span> </a> </span>
              <!-- Code Link. -->
              <span class="link-block"> <a href="https://github.com/xmed-lab/MedRegA"
                   class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span>
              <!-- Dataset Link. -->
              <span class="link-block"> <a href="https://huggingface.co/Luxuriant16/medrega"
                   class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fa fa-database"></i> </span> <span>Model</span></a></span>
                  </div>
          	 </div>
       	   </div>
        </div>
  </div>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
	  <!--
		<div style="text-align: center;">
				<img id="teaser" width="100%" src="static/images/teaser.png">     
			  </div><br>
	  -->
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
		  <style>
			/* 使用渐变颜色实现彩虹字体 */
			.rainbow-text {
			  background: linear-gradient(to right, #7D8ABC, #AD88C6);
			  -webkit-background-clip: text;
			  color: transparent;
			  display: inline-block;
			  font-weight: bold;
			}
		  </style>
          <p>
            Several medical Multimodal Large Languange Models (MLLMs) have been developed to address tasks involving visual images with textual instructions across various medical modalities, achieving impressive results.  Most current medical generalist models are region-agnostic, treating the entire image as a holistic representation. However, they struggle to identify which specific regions they are focusing on when generating a sentence. To mimic the behavior of doctors, who typically begin by reviewing the entire image before concentrating on specific regions for a thorough evaluation, we aim to enhance the capability of medical MLLMs in understanding anatomical regions within entire medical scans.
          </p>
          <p>
            To achieve it, we first formulate <b>Region-Centric tasks</b> and construct a large-scale dataset, <span class="rainbow-text">MedRegInstruct</span>, to incorporate regional information into training. Combining our collected dataset with other medical multimodal corpora for training, we propose a <b>Region-Aware medical MLLM</b>, <span class="rainbow-text">MedRegA</span>, which is the first bilingual generalist medical AI system to simultaneously handle image-level and region-level medical vision-language tasks across a broad range of modalities. Our MedRegA not only enables three region-centric tasks, but also achieves the best performance for visual question answering, report generation and medical image classification over 8 modalities, showcasing significant versatility. Experiments demonstrate that our model can not only <b>accomplish powerful performance across various medical vision-language tasks in bilingual settings</b>, but also <b>recognize and detect structures in multimodal medical scans, boosting the interpretability and user interactivity of medical MLLMs</b>.
        </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
                <div style="text-align: center;">
                  <img id="teaser" width="80%" src="static/images/intro.png">     
                </div>
          </div>
        </div>
      </div>
    </div>

</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-2" style="background: linear-gradient(to right,  #535C91, #B2A4FF); -webkit-background-clip: text; -webkit-text-fill-color: transparent;line-height: 1.5;">
          MedRegA on General Medical Tasks</h2>
          <p>
      <h5 class="title is-4">
        English Report Generation
      </h5>
      <div class="content has-text-justified">
      <p>
      Medical Report Generation task requires the model to generate a detailed report based on the provided medical scan. For English report generation, we evaluate our model on the report generation task for chest X-ray datasets MIMIC-CXR and IU-Xray.
    </p>
  </div>
  <p>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
                  <div style="text-align: center;">
                    <img id="teaser" width="90%" src="static/images/en_report.png">     
                  </div>
            </div>
          </div>
        </div>
      </div>
      </p>
      
      <p>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
                  <div style="text-align: center;">
                    <img id="teaser" width="80%" src="static/images/cxr_example.png">     
                  </div>
            </div>
          </div>
        </div>
      </div>
    </p>
    </div>
    </div>
    </div>
    </section>

    <section class="section hero">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
      <h5 class="title is-4">
        Chinese Report Generation
      </h5>
      <div class="content has-text-justified">
      <p>
        To evaluate the ability of our model in generating medical report in Chinese, we collect Chinese image-report pairs in real clinical scenarios to construct a test dataset covering brain, chest, spine, abdomen and pelvis from the hospital. 
      </p></div>
      <p>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
                  <div style="text-align: center;">
                    <img id="teaser" width="90%" src="static/images/cn_report.png">     
                  </div>
            </div>
          </div>
        </div>
      </div>
    </p>

    <p>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
                  <div style="text-align: center;">
                    <img id="teaser" width="85%" src="static/images/cn_report_generate.png">     
                  </div>
            </div>
          </div>
        </div>
      </div>
    </p>
      </div>
      </div>
      </div>
    </section>

    <section class="section hero">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
      <h5 class="title is-4">
        Visual Question Answering and Diagnosis
      </h5>
      <div class="content has-text-justified">
      <p>
        We demonstrate the results on medical VQA benchmark SLAKE, and disease diagnosis benmarks including VinDr series datasets. To further enhance the model's focus on disease lesions, we employ Regional CoT (w/ Region). The improved results indicate that incorporating regional information assists medical MLLMs to concentrate on specific regions.
      </p></div>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
                  <div style="text-align: center;">
                    <img id="teaser" width="45%" src="static/images/radar.png">     
                  </div>
            </div>
          </div>
        </div>
      </div>
      </div>
      </div>
      </div>
    </section>


    <section class="section hero">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <h2 class="title is-2" style="background: linear-gradient(to right,  #535C91, #B2A4FF); -webkit-background-clip: text; -webkit-text-fill-color: transparent;line-height: 1.5;">
              MedRegA on Region-Centric Tasks</h2>
              <div class="content has-text-justified">
              <p>
            Region-Centric tasks are defined from three perspectives: (1) <b>Region-to-Text Identification</b>, where the model outputs the name of the specified region; (2) <b>Text-to-Region Detection</b>, where the model detects the area of the given organ or anomaly; (3) <b>Grounded Report Generation</b>, where the model generates a report for the medical scan, aligning each description with the corresponding region.
        </p></div>
        </div>
        </div>
        </div>
        </section>

        <section class="section hero">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-full-width">
          <h5 class="title is-4">
            Region-to-Text Identification
          </h5>
          <div class="content has-text-justified">
          <p>
            We categorize the task into (1) structure identification for identifying anatomies such as structures within the brain, heart, lung, abdomen or spine, and (2) lesion identification focusing on abnormalities like tumors and cancers. The model demonstrates a stronger capability of identifying body structures compared to lesions, possibly because anatomies tend to be larger, whereas lesions are subtler and exhibit more variation in shape.
          </p></div>
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column is-full-width">
                <div class="content has-text-justified">
                      <div style="text-align: center;">
                        <img id="teaser" width="80%" src="static/images/r2t.png">     
                      </div>
                </div>
              </div>
            </div>
          </div>
          </div>
          </div>
          </div>
        </section>

        <section class="section hero">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-full-width">
          <h5 class="title is-4">
            Text-to-Region Detection
          </h5>
          <div class="content has-text-justified">
          <p>
            We classify the task into four categories according to the number of detected objects and the number of regions per object: single-object single-region, single-object multi-region, multi-object single-region, and multi-object multi-region.
          </p></div>
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column is-full-width">
                <div class="content has-text-justified">
                      <div style="text-align: center;">
                        <img id="teaser" width="70%" src="static/images/t2r.png">     
                      </div>
                </div>
              </div>
            </div>
          </div>
          </div>
          </div>
          </div>
        </section>


        <section class="section hero">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-full-width">
          <h5 class="title is-4">
            Grounded Report Generation
          </h5>
          <div class="content has-text-justified">
          <p>
            We exemplify the output of MedRegA for the grounded report generation task below.
          </p></div>
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column is-full-width">
                <div class="content has-text-justified">
                      <div style="text-align: center;">
                        <img id="teaser" width="95%" src="static/images/ground_example.png">     
                      </div>
                </div>
              </div>
            </div>
          </div>
          </div>
          </div>
          </div>
        </section>

</body>
</html>
